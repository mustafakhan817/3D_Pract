{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mustafakhan817/3D_Pract/blob/main/new_Portfolio_2_questions_(2024_S1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Z88FfJc9lA_T",
      "metadata": {
        "id": "Z88FfJc9lA_T"
      },
      "source": [
        "## Analysis of an E-commerce Dataset Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hoq0NwA9lA_V",
      "metadata": {
        "id": "hoq0NwA9lA_V"
      },
      "source": [
        "The goal of the second analysis task is to train linear regression models to predict users' ratings towards items. This involves a standard Data Science workflow: exploring data, building models, making predictions, and evaluating results. In this task, we will explore the impacts of feature selections and different sizes of training/testing data on the model performance. We will use another cleaned combined e-commerce sub-dataset that **is different from** the one in “Analysis of an E-commerce Dataset” task 1."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9fd3NU_lA_W",
      "metadata": {
        "id": "f9fd3NU_lA_W"
      },
      "source": [
        "### Import Cleaned E-commerce Dataset\n",
        "The csv file named 'cleaned_ecommerce_dataset.csv' is provided. You may need to use the Pandas method, i.e., `read_csv`, for reading it. After that, please print out its total length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PJrb2gtAlA_W",
      "metadata": {
        "id": "PJrb2gtAlA_W"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pylab as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "t7Vd5wZb7vKo"
      },
      "id": "t7Vd5wZb7vKo",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exe_df = pd.read_csv('/content/drive/MyDrive/Portfolio 2/cleaned_ecommerce_dataset.csv')"
      ],
      "metadata": {
        "id": "h7PdT8IT7xiq"
      },
      "id": "h7PdT8IT7xiq",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(exe_df)"
      ],
      "metadata": {
        "id": "eWlGVkqk8slM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e6d8e1-45d8-4db2-ee69-133417774a85"
      },
      "id": "eWlGVkqk8slM",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2685"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aqbuU6rglA_X",
      "metadata": {
        "id": "aqbuU6rglA_X"
      },
      "source": [
        "### Explore the Dataset\n",
        "\n",
        "* Use the methods, i.e., `head()` and `info()`, to have a rough picture about the data, e.g., how many columns, and the data types of each column.\n",
        "* As our goal is to predict ratings given other columns, please get the correlations between helpfulness/gender/category/review and rating by using the `corr()` method.\n",
        "\n",
        "  Hints: To get the correlations between different features, you may need to first convert the categorical features (i.e., gender, category and review) into numerial values. For doing this, you may need to import `OrdinalEncoder` from `sklearn.preprocessing` (refer to the useful exmaples [here](https://pbpython.com/categorical-encoding.html))\n",
        "* Please provide ___necessary explanations/analysis___ on the correlations, and figure out which are the ___most___ and ___least___ corrleated features regarding rating. Try to ___discuss___ how the correlation will affect the final prediction results, if we use these features to train a regression model for rating prediction. In what follows, we will conduct experiments to verify your hypothesis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W3PImHiElA_X",
      "metadata": {
        "id": "W3PImHiElA_X"
      },
      "outputs": [],
      "source": [
        "exe_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exe_df.info()"
      ],
      "metadata": {
        "id": "hPF93vV8nsYi"
      },
      "id": "hPF93vV8nsYi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder"
      ],
      "metadata": {
        "id": "mxb_KufupQuq"
      },
      "id": "mxb_KufupQuq",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ord_enc = OrdinalEncoder()\n",
        "exe_df[\"gender code\"] = ord_enc.fit_transform(exe_df[[\"gender\"]])"
      ],
      "metadata": {
        "id": "zJmYU6cqpTDY"
      },
      "id": "zJmYU6cqpTDY",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exe_df[\"category code\"] = ord_enc.fit_transform(exe_df[[\"category\"]])\n",
        "exe_df[\"review code\"] = ord_enc.fit_transform(exe_df[[\"review\"]])"
      ],
      "metadata": {
        "id": "uIvUPxrE3LTr"
      },
      "id": "uIvUPxrE3LTr",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_helpfulness_against_rating = exe_df['rating'].corr(exe_df['helpfulness'])\n",
        "print(\"The correlation between helpfulness and rating\" corr_helpfulness_against_rating)"
      ],
      "metadata": {
        "id": "8fK1GIgV3bdq"
      },
      "id": "8fK1GIgV3bdq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Most Correlated Feature:\n",
        "# Category: It has the highest negative correlation (-0.163158) with the rating.\n",
        "# As category values increases, the rating tends to decrease.\n",
        "\n",
        "# 2)Least Correlated Feature(s):\n",
        "# Timestamp and Helpfulness: These features have very low correlations (0.000369 and -0.007523 respectively) with the rating.\n",
        "# This suggests that these features might not be significant predictors of the rating."
      ],
      "metadata": {
        "id": "IsgG9cBprZpl"
      },
      "id": "IsgG9cBprZpl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impact on Prediction Results:\n",
        "# - Category: Given its relatively high correlation, it could be an important feature for predicting ratings.\n",
        "# A regression model may assign more weight to this feature during training, potentially leading to better prediction performance.\n",
        "\n",
        "# - Timestamp and Helpfulness: Since these features have low correlations with the rating,\n",
        "# including them in the regression model may not significantly improve prediction accuracy.\n",
        "# The model might not rely heavily on these features for making predictions."
      ],
      "metadata": {
        "id": "w0-UAVqTs4Or"
      },
      "id": "w0-UAVqTs4Or",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4myP5igslA_Y",
      "metadata": {
        "id": "4myP5igslA_Y"
      },
      "source": [
        "### Split Training and Testing Data\n",
        "* Machine learning models are trained to help make predictions for the future. Normally, we need to randomly split the dataset into training and testing sets, where we use the training set to train the model, and then leverage the well-trained model to make predictions on the testing set.\n",
        "* To further investigate whether the size of the training/testing data affects the model performance, please random split the data into training and testing sets with different sizes:\n",
        "    * Case 1: training data containing 10% of the entire data;\n",
        "    * Case 2: training data containing 90% of the entire data.\n",
        "* Print the shape of training and testing sets in the two cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JIDMig9blA_Y",
      "metadata": {
        "id": "JIDMig9blA_Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#write somethin here before next\n",
        "train_case1,test_case1 = train_test_split(exe_df, test_size=, random_state=42)\n",
        "train_case2,test_case2 = train_test_split(exe_df, test_size=, random_state=42)\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "metadata": {
        "id": "t1zwL31m4sOq"
      },
      "id": "t1zwL31m4sOq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = exe_df.drop(columns=['rating'])\n",
        "y = exe_df['rating']"
      ],
      "metadata": {
        "id": "twt9nHHmuwaJ"
      },
      "id": "twt9nHHmuwaJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ONb__m8RujBf"
      },
      "id": "ONb__m8RujBf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Case 1 Print noyt included\n",
        "print(\"Case 1: Training data containing 10% of the entire data\")\n",
        "print(\"X_train shape:\", X_train_10.shape)\n",
        "print(\"y_train shape:\", y_train_10.shape)\n",
        "print(\"X_test shape:\", X_test_10.shape)\n",
        "print(\"y_test shape:\", y_test_10.shape)\n",
        "print()"
      ],
      "metadata": {
        "id": "DStoDdfUvQFd"
      },
      "id": "DStoDdfUvQFd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Case 2 Print not included\n",
        "print(\"Case 2: Training data containing 90% of the entire data\")\n",
        "print(\"X_train shape:\", X_train_90.shape)\n",
        "print(\"y_train shape:\", y_train_90.shape)\n",
        "print(\"X_test shape:\", X_test_90.shape)\n",
        "print(\"y_test shape:\", y_test_90.shape)"
      ],
      "metadata": {
        "id": "hu3CYvCjvbSr"
      },
      "id": "hu3CYvCjvbSr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "DjSsgT0BlA_Y",
      "metadata": {
        "id": "DjSsgT0BlA_Y"
      },
      "source": [
        "### Train Linear Regression Models with Feature Selection under Cases 1 & 2\n",
        "* When training a machine learning model for prediction, we may need to select the most important/correlated input features for more accurate results.\n",
        "* To investigate whether feature selection affects the model performance, please select two most correlated features and two least correlated features from helpfulness/gender/category/review regarding rating, respectively.\n",
        "* Train four linear regression models by following the conditions:\n",
        "    - (model-a) using the training/testing data in case 1 with two most correlated input features\n",
        "    - (model-b) using the training/testing data in case 1 with two least correlated input features\n",
        "    - (model-c) using the training/testing data in case 2 with two most correlated input features\n",
        "    - (model-d) using the training/testing data in case 2 with two least correlated input features\n",
        "* By doing this, we can verify the impacts of the size of traing/testing data on the model performance via comparing model-a and model-c (or model-b and model-d); meanwhile the impacts of feature selection can be validated via comparing model-a and model-b (or model-c and model-d).    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DASzPUATlA_Z",
      "metadata": {
        "id": "DASzPUATlA_Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#write something her to complete first\n",
        "reg_a = linear_model.LinearRegression()\n",
        "\n",
        "X_train_a = train_case1[['', '']]\n",
        "y_train_a = train_case1['rating']\n",
        "\n",
        "X_test_a = test_case1[['', '']]\n",
        "y_test_a = test_case1['rating']\n",
        "\n",
        "reg_a.fit(X_train_a, y_train_a)"
      ],
      "metadata": {
        "id": "-JomvM-P5eRj"
      },
      "id": "-JomvM-P5eRj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_b = linear_model.LinearRegression()\n",
        "\n",
        "X_train_b = train_case1[['', '']]\n",
        "y_train_b = train_case1['rating']\n",
        "\n",
        "X_test_b = test_case1[['', '']]\n",
        "y_test_b = test_case1['rating']\n",
        "\n",
        "reg_b.fit(X_train_b, y_train_b)"
      ],
      "metadata": {
        "id": "KVOS0n876X7R"
      },
      "id": "KVOS0n876X7R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_c = linear_model.LinearRegression()\n",
        "\n",
        "X_train_c = train_case2[['', '']]\n",
        "y_train_c = train_case2['rating']\n",
        "\n",
        "X_test_c = test_case1[['', '']]\n",
        "y_test_c = test_case1['rating']\n",
        "\n",
        "reg_c.fit(X_train_c, y_train_c)"
      ],
      "metadata": {
        "id": "mLNxcjJz6Ygx"
      },
      "id": "mLNxcjJz6Ygx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_d = linear_model.LinearRegression()\n",
        "\n",
        "X_train_d = train_case2[['', '']]\n",
        "y_train_d = train_case2['rating']\n",
        "\n",
        "X_test_d = test_case1[['', '']]\n",
        "y_test_d = test_case1['rating']\n",
        "\n",
        "reg_d.fit(X_train_d, y_train_d)"
      ],
      "metadata": {
        "id": "Ywu1YN5k603r"
      },
      "id": "Ywu1YN5k603r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "KATSn7hYlA_Z",
      "metadata": {
        "id": "KATSn7hYlA_Z"
      },
      "source": [
        "### Evaluate Models\n",
        "* Evaluate the performance of the four models with two metrics, including MSE and Root MSE\n",
        "* Print the results of the four models regarding the two metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fU8GPS9lA_Z",
      "metadata": {
        "id": "4fU8GPS9lA_Z"
      },
      "outputs": [],
      "source": [
        "predicted_a = reg_a.predict(X_test_a)\n",
        "mse_a = ((np.array(y_test_a)-predicted_a)**2).sum()/len(y_test_a)\n",
        "r2_a = r2_score(y_test_a, predicted_a)\n",
        "print(\"MSE:\", mse_a)\n",
        "print(\"Root MSE:\", np.sqrt(mse_a))\n",
        "print(\"R Squared:\", r2_a)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_a = reg_a.predict(X_test_a)\n",
        "mse_a = ((np.array(y_test_a)-predicted_a)**2).sum()/len(y_test_a)\n",
        "r2_a = r2_score(y_test_a, predicted_a)\n",
        "print(\"MSE:\", mse_a)\n",
        "print(\"Root MSE:\", np.sqrt(mse_a))\n",
        "print(\"R Squared:\", r2_a)"
      ],
      "metadata": {
        "id": "JJmMI_re8hTM"
      },
      "id": "JJmMI_re8hTM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_c = reg_a.predict(X_test_a)\n",
        "mse_a = ((np.array(y_test_a)-predicted_a)**2).sum()/len(y_test_a)\n",
        "r2_a = r2_score(y_test_a, predicted_a)\n",
        "print(\"MSE:\", mse_a)\n",
        "print(\"Root MSE:\", np.sqrt(mse_a))\n",
        "print(\"R Squared:\", r2_a)"
      ],
      "metadata": {
        "id": "BtaGspcF8hha"
      },
      "id": "BtaGspcF8hha",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_d = reg_a.predict(X_test_d)\n",
        "mse_d = ((np.array(y_test_d)-predicted_d)**2).sum()/len(y_test_d)\n",
        "r2_d = r2_score(y_test_d, predicted_d)\n",
        "print(\"MSE:\", mse_d)\n",
        "print(\"Root MSE:\", np.sqrt(mse_d))\n",
        "print(\"R Squared:\", r2_d)"
      ],
      "metadata": {
        "id": "qmLCv3qY81GC"
      },
      "id": "qmLCv3qY81GC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "Y9jx-eY6lA_a",
      "metadata": {
        "id": "Y9jx-eY6lA_a"
      },
      "source": [
        "### Visualize, Compare and Analyze the Results\n",
        "* Visulize the results, and perform ___insightful analysis___ on the obtained results. For better visualization, you may need to carefully set the scale for the y-axis.\n",
        "* Normally, the model trained with most correlated features and more training data will get better results. Do you obtain the similar observations? If not, please ___explain the possible reasons___."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3TNAIGDilA_a",
      "metadata": {
        "id": "3TNAIGDilA_a"
      },
      "outputs": [],
      "source": [
        "#for background and observations 2 diagrams\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9ee01ac",
      "metadata": {
        "id": "f9ee01ac"
      },
      "source": [
        "### Data Science Ethics\n",
        "*Please read the following examples [Click here to read the example_1.](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) [Click here to read the example_2.](https://viborc.com/ethics-and-ethical-data-visualization-a-complete-guide/)\n",
        "\n",
        "*Then view the picture ![My Image](figure_portfolio2.png \"This is my image\")\n",
        "Please compose an analysis of 100-200 words that evaluates potential ethical concerns associated with the infographic, detailing the reasons behind these issues.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44f30e9b",
      "metadata": {
        "id": "44f30e9b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0511889d",
      "metadata": {
        "id": "0511889d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}